{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet1PyTorch.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ch0mxg0l1jcB","colab_type":"code","outputId":"2dbe0e4c-bb21-400a-cb18-cd8b3a44f29c","executionInfo":{"status":"ok","timestamp":1562063127486,"user_tz":-480,"elapsed":1138,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["from __future__ import print_function\n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)\n","from torch.autograd import Variable"],"execution_count":1,"outputs":[{"output_type":"stream","text":["PyTorch Version:  1.1.0\n","Torchvision Version:  0.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IOjsEzd2FX69","colab_type":"text"},"source":["## GPU & mount Google Drive\n"]},{"cell_type":"code","metadata":{"id":"rKZaDuFA1twY","colab_type":"code","outputId":"918724cb-c974-44d0-bc86-584763a3094e","executionInfo":{"status":"ok","timestamp":1562064800027,"user_tz":-480,"elapsed":772,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# with open('/content/gdrive/My Drive/foo.txt', 'w') as f:\n","#   f.write('Hello Google Drive!')\n","# !cat /content/gdrive/My\\ Drive/foo.txt"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KWQ5XZmFPlLZ","colab_type":"text"},"source":["How to use gpu in Colab: https://medium.com/@nrezaeis/pytorch-in-google-colab-640e5d166f13"]},{"cell_type":"code","metadata":{"id":"x8Kd6E1cOn_4","colab_type":"code","outputId":"9f21e570-a29e-4393-ed6c-fceb120b7bbf","executionInfo":{"status":"ok","timestamp":1562063134893,"user_tz":-480,"elapsed":4263,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["#check the version of Cuda and python\n","!nvcc --version\n","!python --version"],"execution_count":3,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2018 NVIDIA Corporation\n","Built on Sat_Aug_25_21:08:01_CDT_2018\n","Cuda compilation tools, release 10.0, V10.0.130\n","Python 3.6.8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ktHECOgZPr0H","colab_type":"text"},"source":["command: https://pytorch.org/"]},{"cell_type":"code","metadata":{"id":"FgQwr9RrPMKv","colab_type":"code","outputId":"49cb1399-242a-48d2-e74f-e371d79c89a9","executionInfo":{"status":"ok","timestamp":1562063169608,"user_tz":-480,"elapsed":7954,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":161}},"source":["!pip3 install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n","!pip3 install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch==1.1.0 from https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.16.4)\n","Requirement already satisfied: torchvision==0.3.0 from https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (4.3.0)\n","Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.16.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.12.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.3.0) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"izNtrWB3PzaQ","colab_type":"code","outputId":"ff5057f7-d75a-4fca-e488-8ce8ccab2e7b","executionInfo":{"status":"ok","timestamp":1562063170803,"user_tz":-480,"elapsed":940,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["torch.cuda.get_device_name(0)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla K80'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"erggMQGk1xr1","colab_type":"text"},"source":["# Global Variables"]},{"cell_type":"code","metadata":{"id":"j_89bKf-1u2l","colab_type":"code","colab":{}},"source":["IMAGENET_MEAN = [0.485, 0.456, 0.406]\n","IMAGENET_STD = [0.229, 0.224, 0.225]\n","\n","model_name = 'resnet'\n","\n","# Number of classes in the dataset\n","num_classes = 10\n","\n","# Batch size for training (change depending on how much memory you have)\n","batch_size = 32\n","\n","# Number of epochs to train for\n","num_epochs = 20\n","\n","# Flag for feature extracting. When False, we finetune the whole model,\n","#   when True we only update the reshaped layer params\n","feature_extract = False\n","\n","input_size = 224\n","\n","num_workers = 4\n","\n","device = torch.device(\"cuda\")\n","use_gpu=True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8wi5MGFt16JV","colab_type":"text"},"source":["# Helper Functions"]},{"cell_type":"markdown","metadata":{"id":"5JL59Lfq1821","colab_type":"text"},"source":["## Model training and validation code\n","Use of fstring to concatenate strings: https://realpython.com/python-f-strings/"]},{"cell_type":"code","metadata":{"id":"mkO2-wjR18CB","colab_type":"code","colab":{}},"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    \n","#     model_save_name = f\"{num_epochs}.pt\"\n","#     PATH= f\"gdrive/My Drive/201906AI_FinalProject/checkpoints_resnet18/{model_save_name}\"\n","#     torch.save({'epoch': 0, 'model_state_dict': model.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'loss': 0}, PATH)\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\"\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)                  \n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    if is_inception and phase == 'train':\n","                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n","                        outputs, aux_outputs = model(inputs)\n","                        loss1 = criterion(outputs, labels)\n","                        loss2 = criterion(aux_outputs, labels)\n","                        loss = loss1 + 0.4*loss2\n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","\n","        print()\n","    \n","#     model_save_name = f\"{epoch}.pt\"\n","#     PATH= f\"gdrive/My Drive/201906AI_FinalProject/checkpoints_resnet18/{model_save_name}\"\n","#     torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'loss': loss}, PATH)\n","    \n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YYzx7Rw42N3X","colab_type":"text"},"source":["## Set Model Parameters' requires_grad attribute"]},{"cell_type":"code","metadata":{"id":"IIA5l1rh2JP9","colab_type":"code","colab":{}},"source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g7JrylRm2QVe","colab_type":"text"},"source":["# Initialize and reshape the network"]},{"cell_type":"code","metadata":{"id":"9TJg2gsW2T6T","colab_type":"code","outputId":"241d984d-9723-43e0-9118-6aec8a274674","executionInfo":{"status":"ok","timestamp":1562063181128,"user_tz":-480,"elapsed":1139,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","    input_size = 0\n","\n","    model_ft = models.resnet18(pretrained=use_pretrained)\n","    set_parameter_requires_grad(model_ft, feature_extract)\n","    num_ftrs = model_ft.fc.in_features\n","    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","    input_size = 224\n","\n","    return model_ft, input_size\n","\n","# Initialize the model for this run\n","model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n","\n","# Print the model we just instantiated\n","print(model_ft)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HA7WRLUk3CY3","colab_type":"text"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"w_Qh5f6R2YCN","colab_type":"code","outputId":"ae8ef18d-49af-4323-eb44-7b9c969fb9b9","executionInfo":{"status":"ok","timestamp":1562063183273,"user_tz":-480,"elapsed":788,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["data_transforms = {\n","    'train': transforms.Compose([\n","        # Data augmentation is a good practice for the train set\n","        # Here, we randomly crop the image to 224x224 and\n","        # randomly flip it horizontally. \n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(224), \n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","    ]),\n","    'test': transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","    ])\n","}\n","\n","train_dir = 'gdrive/My Drive/201906AI_FinalProject/data_all/images/train'\n","val_dir = 'gdrive/My Drive/201906AI_FinalProject/data_all/images/val'\n","test_dir =  'gdrive/My Drive/201906AI_FinalProject/data_all/images/test'\n","\n","train_dset =  datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n","train_loader = torch.utils.data.DataLoader(train_dset,\n","                     batch_size=batch_size,\n","                     num_workers=num_workers,\n","                     shuffle=True)\n","\n","val_dset =  datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n","val_loader =torch.utils.data.DataLoader(val_dset,\n","                  batch_size=batch_size,\n","                  num_workers=num_workers)\n","\n","test_dset =  datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n","test_loader = torch.utils.data.DataLoader(test_dset,\n","                     batch_size=batch_size,\n","                     num_workers=num_workers,\n","                     shuffle=True)\n","\n","image_datasets = {'train': train_dset, 'val':val_dset, 'test': test_dset}\n","dataloaders_dict = {'train': train_loader, 'val':val_loader, 'test':test_loader}\n","\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train','val', 'test']}\n","\n","for x in ['train', 'val', 'test']:\n","    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n","    \n","print(\"Classes: \")\n","class_names = image_datasets['test'].classes\n","print(image_datasets['test'].classes)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Loaded 12454 images under train\n","Loaded 4570 images under val\n","Loaded 489 images under test\n","Classes: \n","['BernardPicart', 'GeorgeHendrikBreitner', 'IsaacIsraels', 'JanLuyken', 'JohannesTavenraat', 'MariusBauer', 'ReinierVinkeles', 'RembrandtHarmenszvanRijn', 'SimonFokke', 'WillemWitsen']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iTaHdz5T3l0_","colab_type":"text"},"source":["# Opitimizer"]},{"cell_type":"code","metadata":{"id":"n6EoR_vK3O9B","colab_type":"code","outputId":"0d6358b9-a558-4484-b935-63fe7194094b","executionInfo":{"status":"ok","timestamp":1562063191273,"user_tz":-480,"elapsed":6182,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Send the model to GPU\n","model_ft = model_ft.to(device)\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model_ft.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t conv1.weight\n","\t bn1.weight\n","\t bn1.bias\n","\t layer1.0.conv1.weight\n","\t layer1.0.bn1.weight\n","\t layer1.0.bn1.bias\n","\t layer1.0.conv2.weight\n","\t layer1.0.bn2.weight\n","\t layer1.0.bn2.bias\n","\t layer1.1.conv1.weight\n","\t layer1.1.bn1.weight\n","\t layer1.1.bn1.bias\n","\t layer1.1.conv2.weight\n","\t layer1.1.bn2.weight\n","\t layer1.1.bn2.bias\n","\t layer2.0.conv1.weight\n","\t layer2.0.bn1.weight\n","\t layer2.0.bn1.bias\n","\t layer2.0.conv2.weight\n","\t layer2.0.bn2.weight\n","\t layer2.0.bn2.bias\n","\t layer2.0.downsample.0.weight\n","\t layer2.0.downsample.1.weight\n","\t layer2.0.downsample.1.bias\n","\t layer2.1.conv1.weight\n","\t layer2.1.bn1.weight\n","\t layer2.1.bn1.bias\n","\t layer2.1.conv2.weight\n","\t layer2.1.bn2.weight\n","\t layer2.1.bn2.bias\n","\t layer3.0.conv1.weight\n","\t layer3.0.bn1.weight\n","\t layer3.0.bn1.bias\n","\t layer3.0.conv2.weight\n","\t layer3.0.bn2.weight\n","\t layer3.0.bn2.bias\n","\t layer3.0.downsample.0.weight\n","\t layer3.0.downsample.1.weight\n","\t layer3.0.downsample.1.bias\n","\t layer3.1.conv1.weight\n","\t layer3.1.bn1.weight\n","\t layer3.1.bn1.bias\n","\t layer3.1.conv2.weight\n","\t layer3.1.bn2.weight\n","\t layer3.1.bn2.bias\n","\t layer4.0.conv1.weight\n","\t layer4.0.bn1.weight\n","\t layer4.0.bn1.bias\n","\t layer4.0.conv2.weight\n","\t layer4.0.bn2.weight\n","\t layer4.0.bn2.bias\n","\t layer4.0.downsample.0.weight\n","\t layer4.0.downsample.1.weight\n","\t layer4.0.downsample.1.bias\n","\t layer4.1.conv1.weight\n","\t layer4.1.bn1.weight\n","\t layer4.1.bn1.bias\n","\t layer4.1.conv2.weight\n","\t layer4.1.bn2.weight\n","\t layer4.1.bn2.bias\n","\t fc.weight\n","\t fc.bias\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MdZ8JCix3z83","colab_type":"text"},"source":["# Run Training an validation step"]},{"cell_type":"code","metadata":{"id":"aM0RbvjMM_Dd","colab_type":"code","colab":{}},"source":["# Setup the loss fxn\n","criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7eoBeSmt3o7t","colab_type":"code","outputId":"7eb9a8b0-8b48-466a-be73-3a62ccad0e19","executionInfo":{"status":"ok","timestamp":1561760561357,"user_tz":-480,"elapsed":22091385,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Train and evaluate\n","model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))#9:55"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 0/19\n","----------\n","train Loss: 1.0593 Acc: 0.6337\n","val Loss: 0.7578 Acc: 0.7322\n","\n","Epoch 1/19\n","----------\n","train Loss: 0.6574 Acc: 0.7691\n","val Loss: 0.7354 Acc: 0.7348\n","\n","Epoch 2/19\n","----------\n","train Loss: 0.5428 Acc: 0.8152\n","val Loss: 0.5584 Acc: 0.8007\n","\n","Epoch 3/19\n","----------\n","train Loss: 0.4829 Acc: 0.8275\n","val Loss: 0.9409 Acc: 0.6768\n","\n","Epoch 4/19\n","----------\n","train Loss: 0.4281 Acc: 0.8502\n","val Loss: 0.5180 Acc: 0.8241\n","\n","Epoch 5/19\n","----------\n","train Loss: 0.3966 Acc: 0.8594\n","val Loss: 0.4125 Acc: 0.8626\n","\n","Epoch 6/19\n","----------\n","train Loss: 0.3651 Acc: 0.8749\n","val Loss: 0.5112 Acc: 0.8387\n","\n","Epoch 7/19\n","----------\n","train Loss: 0.3414 Acc: 0.8813\n","val Loss: 0.5763 Acc: 0.8162\n","\n","Epoch 8/19\n","----------\n","train Loss: 0.3187 Acc: 0.8895\n","val Loss: 0.5103 Acc: 0.8335\n","\n","Epoch 9/19\n","----------\n","train Loss: 0.2993 Acc: 0.8951\n","val Loss: 0.6369 Acc: 0.8026\n","\n","Epoch 10/19\n","----------\n","train Loss: 0.2848 Acc: 0.9002\n","val Loss: 0.4871 Acc: 0.8403\n","\n","Epoch 11/19\n","----------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OD5awxyICQLK","colab_type":"text"},"source":["# Test \n","https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"]},{"cell_type":"code","metadata":{"id":"IxhGLdAvbTok","colab_type":"code","colab":{}},"source":["ckpath = \"gdrive/My Drive/201906AI_FinalProject/checkpoints_resnet18/19.pt\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJ8o513cbTiS","colab_type":"code","outputId":"391de28f-cbc3-4ea1-eab8-53bcf218ffa7","executionInfo":{"status":"ok","timestamp":1562063832974,"user_tz":-480,"elapsed":2564,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["#     model_save_name = f\"{epoch}.pt\"\n","#     PATH= f\"gdrive/My Drive/201906AI_FinalProject/checkpoints_resnet18/{model_save_name}\"\n","#     torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'loss': loss}, PATH)\n","\n","print('===> Try resume from checkpoint')\n","\n","checkpoint = torch.load(ckpath)\n","model_ft.load_state_dict(checkpoint['model_state_dict'])\n","optimizer_ft.load_state_dict(checkpoint['optimizer_state_dict'])\n","epoch = checkpoint['epoch']\n","loss = checkpoint['loss']\n","print('===> Load last checkpoint data')\n","\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["===> Try resume from checkpoint\n","===> Load last checkpoint data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pNymz1MDQCaF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"1c19c9d7-83d3-43ea-a5fe-2a9d4dde826b","executionInfo":{"status":"ok","timestamp":1562063832976,"user_tz":-480,"elapsed":937,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}}},"source":["print(loss)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["tensor(1.7806, device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yV1xEE2GCQiP","colab_type":"code","outputId":"1743db91-b918-407e-85e4-37cab3052ef3","executionInfo":{"status":"ok","timestamp":1562063911326,"user_tz":-480,"elapsed":579,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# 设置为评估模式\n","model_ft.eval()"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"JAgmxWrKBI2T","colab_type":"code","outputId":"1b1e3942-b6af-4493-b1aa-bbd991e3ed29","executionInfo":{"status":"ok","timestamp":1562063973216,"user_tz":-480,"elapsed":58166,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model_ft(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += torch.sum(predicted == labels)\n","\n","    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n","    \n"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Test Accuracy of the model on the test images: 93 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V5H6EASFw1I_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"bc0e8d33-c30a-496b-d1cd-521325bedb4a","executionInfo":{"status":"ok","timestamp":1562065276454,"user_tz":-480,"elapsed":60241,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}}},"source":["class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        model_ft = model_ft.to(device)\n","        outputs = model_ft(images)\n","        _, predicted = torch.max(outputs, 1)\n","        c = (predicted == labels).squeeze()\n","        for i in range(9):\n","            label = labels[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","\n","\n","for i in range(10):\n","    if class_total[i]==0:\n","      continue\n","    print('Accuracy of %5s : %2d %%' % (image_datasets['test'].classes[i], 100 * class_correct[i] / class_total[i]))"],"execution_count":53,"outputs":[{"output_type":"stream","text":["Accuracy of BernardPicart : 87 %\n","Accuracy of GeorgeHendrikBreitner :  0 %\n","Accuracy of JanLuyken : 93 %\n","Accuracy of ReinierVinkeles : 62 %\n","Accuracy of RembrandtHarmenszvanRijn : 100 %\n","Accuracy of SimonFokke : 93 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kojkPbqgRqeH","colab_type":"text"},"source":["# 测试风格迁移后的图片"]},{"cell_type":"code","metadata":{"id":"j4exhkoeRtdM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"851f41b0-3973-4fa4-bf85-a3df32b07d0a","executionInfo":{"status":"ok","timestamp":1562065320813,"user_tz":-480,"elapsed":1150,"user":{"displayName":"Dailin Geng","photoUrl":"","userId":"10221960008303902472"}}},"source":["# with torch.no_grad():\n","#     correct = 0\n","#     total = 0\n","#     for images, labels in test_loader:\n","#         images = images.to(device)\n","#         labels = labels.to(device)\n","#         outputs = model_ft(images)\n","#         _, predicted = torch.max(outputs, 1)\n","#         total += labels.size(0)\n","#         correct += torch.sum(predicted == labels)\n","\n","#     print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n","    \n","imagepath = \"gdrive/My Drive/201906AI_FinalProject/StyleTransfer/results\"\n","with torch.no_grad():\n","  test1_dset = datasets.ImageFolder(imagepath, transform=data_transforms['test'])\n","  test1_loader = torch.utils.data.DataLoader(test1_dset,\n","                     batch_size=batch_size,\n","                     num_workers=num_workers,\n","                     shuffle=True)\n","  for images, labels in test1_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model_ft(images)\n","        _, predicted = torch.max(outputs, 1)\n","        print(\"Predicted results:\", predicted)\n"," "],"execution_count":57,"outputs":[{"output_type":"stream","text":["Predicted results: tensor([5, 5, 1], device='cuda:0')\n"],"name":"stdout"}]}]}